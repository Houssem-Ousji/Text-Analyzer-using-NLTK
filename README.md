# Text-Analyzer-using-NLTK
Its a python scripts(class task) which contain two part:
### the indexing phase:
<ul>
  <li>word tokenization</li>
  <li>line tokenization</li>
  <li>deleting stop words</li>
  <li>word racinisation</li>
  <li>word lemmatisation</li>
  <li>word labeling</li>
</ul>
<br>

### the research phase:
<ul>
  <li>getting The list of documents containing a given word</li>
  <li>getting The number of occurrences of a given word in each returned document</li>
  <li>getting The weight of a given word in each returned document</li>
  <li>getting The tf-idf of a given word in each returned document</li>
  <li>getting The most relevant document for a given word</li>
</ul>
